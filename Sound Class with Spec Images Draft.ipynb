{"cells":[{"metadata":{"_uuid":"58a78aa9939abef7ee8cbf2e02ab525beede0585"},"cell_type":"markdown","source":"# Urban Sound Classification\n8732 labeled sound excerpts of urban sounds classified into 10 classes using Keras"},{"metadata":{"_uuid":"96943013e215fb407a349d69e940fc1e7dff3578"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"85f843b212ebbc7e7bbcc4e3fa406443c68cedd3"},"cell_type":"markdown","source":"## Importing Basic Libraries and Installing Tools Required"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"%matplotlib inline\nfrom memory_profiler import memory_usage\nimport os\nimport pandas as pd\nfrom glob import glob\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09271a053e281dfc16252926dd1bad77ce7bbbc0"},"cell_type":"markdown","source":"\n### Installing libav-tools to get Librosa Working Properly"},{"metadata":{"trusted":true,"_uuid":"e65b0eb0077460f117a3148493ad887ac7e6037e"},"cell_type":"code","source":"%%capture\n!apt-get install libav-tools -y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3daa5ab32c049dce1fec83d8c180d62b7f523a2f"},"cell_type":"markdown","source":"### Importing Keras for Deep Learning and Librosa for Creating Spectrogram"},{"metadata":{"trusted":true,"_uuid":"b7f4ca234dc0f182b0738eda27f7a8d913624779"},"cell_type":"code","source":"\nfrom keras import layers\nfrom keras import models\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam\nimport keras.backend as K\nimport librosa\nimport librosa.display\nimport pylab\nimport matplotlib.pyplot as plt\nfrom matplotlib import figure\nimport gc\nfrom path import Path","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a4d7f4b7e3ebbb578f380be6ef9e8a601f2d629"},"cell_type":"markdown","source":"### Making Temporary Working Directories for Storing the Audio Conversions"},{"metadata":{"trusted":true,"_uuid":"5ed95c35fb1ba38f4b5ed5d5631d14339bc7a813","scrolled":true},"cell_type":"code","source":"!mkdir /kaggle/working/train\n!mkdir /kaggle/working/test\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3b5f32ecf6ba74a889e271a974a6e5f372871e8"},"cell_type":"markdown","source":"## Defining the Create Spectrogram Function\nUtilizes the Librosa library in order to convert a spectrogram into an image for CNN classification. \n#'/kaggle/working/train/'\n#'/kaggle/working/test/'"},{"metadata":{"trusted":true,"_uuid":"95e214ba7b173fd9e5d8b0f4f8d69e09ad657630"},"cell_type":"code","source":"def create_spectrogram(filename,name):\n    plt.interactive(False)\n    clip, sample_rate = librosa.load(filename, sr=None)\n    fig = plt.figure(figsize=[0.72,0.72])\n    ax = fig.add_subplot(111)\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    ax.set_frame_on(False)\n    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n    filename  = '/kaggle/working/train/' + name + '.jpg'\n    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n    plt.close()    \n    fig.clf()\n    plt.close(fig)\n    plt.close('all')\n    del filename,name,clip,sample_rate,fig,ax,S","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b58e9171499d4b39992318a0a039e617626e9d2a"},"cell_type":"code","source":"def create_spectrogram_test(filename,name):\n    plt.interactive(False)\n    clip, sample_rate = librosa.load(filename, sr=None)\n    fig = plt.figure(figsize=[0.72,0.72])\n    ax = fig.add_subplot(111)\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    ax.set_frame_on(False)\n    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n    filename  = Path('/kaggle/working/test/' + name + '.jpg')\n    fig.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n    plt.close()    \n    fig.clf()\n    plt.close(fig)\n    plt.close('all')\n    del filename,name,clip,sample_rate,fig,ax,S","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9ce2e26375972e09b895aad8cd2ae146470a23e"},"cell_type":"markdown","source":"### Splitting the Conversion in different cells and collecting the garbage to avoid Ram Overflow - TOO MUCH WORK"},{"metadata":{"trusted":true,"_uuid":"c6099dc3c5fc83b4108bf4e1fe7f84ef3c923779"},"cell_type":"code","source":"Data_dir=np.array(glob(\"../input/train/Train/*\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03413a7044c5428c3e882a449eff2aa47851b181"},"cell_type":"code","source":"%load_ext memory_profiler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7159f9cebe7d3b61baf3bf155610055d67e214d4","scrolled":false},"cell_type":"code","source":"%%memit \ni=0\nfor file in Data_dir[i:i+2000]:\n    #Define the filename as is, \"name\" refers to the JPG, and is split off into the number itself. \n    filename,name = file,file.split('/')[-1].split('.')[0]\n    create_spectrogram(filename,name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e5503be15c42d8f989346789df267331184994b","scrolled":true},"cell_type":"code","source":"%%memit \ni=2000\nfor file in Data_dir[i:i+2000]:\n    filename,name = file,file.split('/')[-1].split('.')[0]\n    create_spectrogram(filename,name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61ddd53c496bb225caeea1ee3fc56bd6a438ea4a"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4d5b9f808e4b9ce93c76e3ebd2f41684cd52507","scrolled":true},"cell_type":"code","source":"%%memit \ni=4000\nfor file in Data_dir[i:]:\n    filename,name = file,file.split('/')[-1].split('.')[0]\n    create_spectrogram(filename,name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c42a93f7f14d8ff04090cddec3e5f7c6864a7f1"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbbd2e78bd69f5c655f13d999b34c290ac42ed20","scrolled":true},"cell_type":"code","source":"#We change the ids for the images in the csv files to reflect their new status as jpgs\n#https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\nfrom keras_preprocessing.image import ImageDataGenerator\n#Important to note that since we converted all of our images within our session, theyre stored in the working directory\ndef append_ext(fn):\n    return fn+\".jpg\"\n\ntraindf=pd.read_csv('../input/train.csv',dtype=str)\ntestdf=pd.read_csv('../input/test.csv',dtype=str)\ntraindf[\"ID\"]=traindf[\"ID\"].apply(append_ext)\ntestdf[\"ID\"]=testdf[\"ID\"].apply(append_ext)\n\ndatagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n\n\ntrain_generator=datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"/kaggle/working/train/\",\n    x_col=\"ID\",\n    y_col=\"Class\",\n    subset=\"training\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(64,64))\n\nvalid_generator=datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"/kaggle/working/train/\",\n    x_col=\"ID\",\n    y_col=\"Class\",\n    subset=\"validation\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(64,64))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63b48f95754e02b69978cd19151edaafc90d03f5"},"cell_type":"markdown","source":"## Creating Data Bunch for Training and Creating a Resnet34 Model"},{"metadata":{"trusted":true,"_uuid":"b82983c8f61c265657aa8cb1c873785f4621d85c"},"cell_type":"code","source":"#Building model with keras\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers, optimizers\nimport pandas as pd\nimport numpy as np\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(64,64,3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"358194faa2bda20020ea6192991333932ce263c8","scrolled":false},"cell_type":"code","source":"#Fitting keras model, no test gen for now\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=150\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2c897a62f9e12134c358a7633a3613f07e7b15a"},"cell_type":"code","source":"#Evaluate GEnerator\nmodel.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8938e47527547c64f1ead14506a2ebef75432cc"},"cell_type":"markdown","source":"## Testing"},{"metadata":{"trusted":true,"_uuid":"f1a7b41b52874b12962a6e95dede0c5f1a7ecbb0"},"cell_type":"code","source":"Test_dir=np.array(glob(\"../input/test/Test/*\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d6dc7004c1f41552bbac9d70b985c8abe11d8ad"},"cell_type":"code","source":"%%memit \ni=0\nfor file in Test_dir[i:i+1500]:\n    filename,name = file,file.split('/')[-1].split('.')[0]\n    create_spectrogram_test(filename,name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d8439b0b8439235b96e23ecd8cb7a7fbadd1c9b"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b30170499762fac307908b7ede5fb4852ead9747"},"cell_type":"code","source":"%%memit \ni=1500\nfor file in Test_dir[i:]:\n    filename,name = file,file.split('/')[-1].split('.')[0]\n    create_spectrogram_test(filename,name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f079adcbab1c59918fbdafcd79c659ce2495fbe"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88d4732aff727a6de7becf8d0bf77a0ef599c0df"},"cell_type":"code","source":"test_datagen=ImageDataGenerator(rescale=1./255.)\ntest_generator=test_datagen.flow_from_dataframe(\n    dataframe=testdf,\n    directory=\"/kaggle/working/test/\",\n    x_col=\"ID\",\n    y_col=None,\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=None,\n    target_size=(64,64))\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n\n\ntest_generator.reset()\npred=model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b905aca0bb936d12d00c052e754eadffc530247"},"cell_type":"markdown","source":"## Making predictions and writing it to CSV"},{"metadata":{"trusted":true,"_uuid":"b48007cb1c20925e724b435c213ae72ff88030b3"},"cell_type":"code","source":"\n#new code, for old code see original kaggle\n\n\npredicted_class_indices=np.argmax(pred,axis=1)\n\n#Fetch labels from train gen for testing\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\nprint(predictions[0:10])\nprint(testdf.head(10))\n\n#Add in sound playing capability, specify original folder\nimport IPython.display as ipd\n\n#test_df['file'] = test_df['ID'].apply(lambda x: test_folder+'/'+str(x)+'.wav')\n\n#Consult https://www.kaggle.com/zhoulingyan0228/reading-24-bit-urban-sound-cnn for the correct sounds\n#This needs a bit more work because we need to convert string wav files or something into floats using the link above\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8fadc76b9c8a1b2f5630a6d82911dd41ed231db"},"cell_type":"code","source":"#Forget about the CSVs for now. We will simply print some things out. maybe top 10 or 20.\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39e6dd92fd3a692c621217eeb106068122c02d41"},"cell_type":"markdown","source":"### Removing Unwanted Folders"},{"metadata":{"trusted":true,"_uuid":"c6b94bb83c3022b7d222b8b6b3f73cc989839ab9"},"cell_type":"code","source":"%%capture\n!apt-get install zip\n!zip -r train.zip /kaggle/working/train/\n!zip -r test.zip /kaggle/working/test/\n!rm -rf train/*\n!rm -rf test/*","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}